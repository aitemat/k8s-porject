# Auto Scaling
Kubernetes có tính năng tự động scale ứng dụng của bạn và quản lý chúng, được gọi là tự động scaling hoặc auto scaling. Tự động scaling giúp tận dụng tài nguyên của hệ thống hiệu quả hơn và đảm bảo ứng dụng của bạn đáp ứng nhu cầu của người dùng.  

Có hai loại tự động scaling trên Kubernetes:
Nói về scale thì có 2 cách scale là horizontal scaling và vertical scaling:  
- `Horizontal Pod Autoscaler (HPA)` là cách scale mà ta sẽ tăng số lượng worker (application) đang xử lý công việc hiện tại ra nhiều hơn. Ví dụ ta đang có 2 Pod để xử lý tích điểm cho client khi client tạo deal thành công, khi số lượng client tăng đột biến, 2 Pod hiện tại không thể xử lý kịp, ta sẽ scale số lượng Pod lên thành 4 Pod chẳng hạn (add và remove pods)    
- `Vertical Pod Autoscaler (VPA)` là cách scale thay vì tăng số lượng worker lên, ta sẽ tăng số lượng tài nguyên có thể sử dụng của ứng dụng đó lên, như là tăng số lượng cpu và memory của ứng dụng đó. Ví dụ ta có một model để train AI, thì việc train AI này ta không thể tách ra một model khác để tăng tốc độ train được, mà ta chỉ có thể tăng cpu và memory cho model đó. (tăng giảm CPU và memory pod).
- `Cluster Autoscaler (CA)`là một controller trong Kubernetes, có chức năng tự động điều chỉnh kích thước của các node trong cluster (cluster scaling) dựa trên nhu cầu thực tế của ứng dụng. Khi sử dụng CA, nếu các pod trong cluster không thể được lập lịch vào các node hiện có, CA sẽ tạo ra các node mới để đáp ứng nhu cầu, và tương tự nếu có quá nhiều node thì CA có thể thu hẹp lại kích thước của cluster bằng cách loại bỏ các node không cần thiết. Các hoạt động của CA được xác định dựa trên các thuật toán thông minh để đảm bảo hiệu quả và an toàn cho hệ thống. (add và remove node)

## 1. Horizontal Pod Autoscaler (HPA): tự động scale các Pod trong một Deployment, ReplicaSet, hoặc StatefulSet dựa trên CPU sử dụng, memory sử dụng, hoặc số lượng kết nối đến ứng dụng.
### HPA LÀ GÌ?
(HPA) là một tính năng của Kubernetes cho phép tự động điều chỉnh số lượng pods của một deployment, replica set hoặc stateful set dựa trên tải hoạt động của ứng dụng. HPA sử dụng các chỉ số như CPU sử dụng hoặc số lượng requests đang được xử lý để phát hiện tải hoạt động và điều chỉnh số lượng replica trong cluster.

HPA hoạt động như sau:

- Khi tải vượt quá hạn mức trên, HPA sẽ tự động tăng số lượng replicas để đáp ứng nhu cầu và đảm bảo khả năng sẵn sàng của ứng dụng.  
- Khi tải giảm xuống, HPA sẽ giảm số lượng replicas để tiết kiệm tài nguyên hệ thống.  

HPA cài đặt như một tài nguyên và được sử dụng với một số đối tượng như deployments, replica sets, hoặc stateful sets. HPA có thể được cấu hình để theo dõi một số chỉ số, chẳng hạn như độ sử dụng CPU hoặc số lượng traffic đang được xử lý bởi service của ứng dụng, và điều chỉnh số lượng replicas dựa trên các chỉ số đó.  

Để sử dụng Horizontal Pod Autoscaler, bạn có thể thực hiện các bước sau:

1. Khai báo một tài nguyên HPA trong file YAML để chỉ định các thông số scale.

2. Cấu hình hệ thống để sử dụng một bộ điều khiển để theo dõi và tính toán các thông số scale (ví dụ như Heapster).

3. Cài đặt metric server (nếu chưa cài đặt) để theo dõi các metric của các Pod.

4. Kích hoạt tự động scaling cho Pod với lệnh `kubectl autoscale deployment <tên deployment> --cpu-percent=<giá trị> --min=<tối thiểu> --max=<tối đa>`

Ví dụ:
`kubectl autoscale deployment nginx-example --cpu-percent=50 --min=2 --max=5`


Trong đó, giá trị cpu-percent là giá trị phần trăm của CPU sử dụng trung bình trên một pod, min và max là giới hạn tối thiểu và tối đa số lượng Pod. Khi CPU sử dụng trung bình trên các Pod vượt qua ngưỡng này, Kubernetes sẽ tự động tạo thêm các Pod mới để đáp ứng với nhu cầu tải.

Bạn có thể sử dụng lệnh kubectl get hpa để kiểm tra trạng thái của tự động scaling của deployment.

Sau đó, để test tự động scaling, bạn có thể tạo một áp lực tải trên các Pod để CPU sử dụng trung bình vượt qua ngưỡng. Có thể sử dụng công cụ hey để thực hiện điều này. Để cài đặt hey, bạn có thể chạy lệnh sau:

`go get -u github.com/rakyll/hey`


Sau khi cài đặt, bạn có thể sử dụng hey để tạo một áp lực tải trên các Pod như sau:

`hey -n 10000 -c 50 http://<IP or Hostname>`


Với lệnh trên, hey sẽ tạo 10.000 yêu cầu HTTP cho địa chỉ IP hoặc tên miền được chỉ định (<IP or Hostname>), với đường truyền tối đa là 50 yêu cầu đồng thời.

Sau khi tạo áp lực tải, chạy lệnh kubectl get hpa để xem số lượng các Pod đã được thêm vào để đáp ứng yêu cầu tải.

Nếu bạn muốn điều chỉnh cấu hình tự động scaling để phù hợp với nhu cầu của ứng dụng của mình, bạn có thể chỉnh sửa tài nguyên HPA hoặc sử dụng các giải pháp auto scaling khác như Cluster Autoscaler hay Vertical Pod Autoscaler.  
 
  
## 2. Vertical Pod Autoscaler (VPA): tự động scale các Container trong một Pod dựa trên yêu cầu memory và CPU sử dụng của các Container.
 `Vertical Pod Autoscaler` (VPA) là một công cụ tự động scale các Container trong một Pod dựa trên yêu cầu sử dụng memory và CPU của các Container. Nó được thiết kế để giải quyết vấn đề về người quản trị hệ thống phải cấu hình lại tài nguyên để đáp ứng nhu cầu sử dụng của các ứng dụng.
### Cách hoạt động
Bộ điều khiển VPA quan sát việc sử dụng tài nguyên của một ứng dụng. Sau đó, bằng cách sử dụng thông tin sử dụng đó làm cơ sở, VPA đề xuất các giá trị giới hạn dưới, giới hạn trên và mục tiêu cho các yêu cầu tài nguyên cho các nhóm ứng dụng đó.

Nói một cách đơn giản, chúng ta có thể tóm tắt quy trình làm việc của VPA như sau:  
`Quan sát việc sử dụng tài nguyên` → `đề xuất yêu cầu tài nguyên` → `cập nhật tài nguyên`  
 
 <img src="/images/VPA.jpg">  
 
 Tùy thuộc vào cách bạn định cấu hình VPA, nó có thể:

Áp dụng trực tiếp các đề xuất bằng cách cập nhật/tạo lại các nhóm ( `updateMode = auto`).
Lưu trữ các giá trị được đề xuất để tham khảo ( `updateMode = off`).
Chỉ áp dụng các giá trị được đề xuất cho các nhóm mới tạo ( `updateMode = initial`).
Hãy nhớ rằng `updateMode = auto` bạn có thể sử dụng trong môi trường thử nghiệm hoặc dàn dựng nhưng không được sử dụng trong sản xuất. Lý do là nhóm khởi động lại khi VPA áp dụng thay đổi, điều này gây ra gián đoạn khối lượng công việc.

Chúng ta nên thiết lập `updateMode = off` trong sản xuất, cung cấp các đề xuất cho bảng điều khiển giám sát dung lượng, chẳng hạn như Grafana và áp dụng các đề xuất trong chu kỳ triển khai tiếp theo.
### Cách sử dụng VPA
Đây là một Triển khai Kubernetes mẫu sử dụng VPA cho các đề xuất tài nguyên.

Trước tiên, hãy tạo tài nguyên Triển khai bằng cách sử dụng tệp kê khai YAML sau được hiển thị bên dưới. Lưu ý rằng không có yêu cầu CPU hoặc bộ nhớ. Các nhóm trong Triển khai thuộc về VerticalPodAutoscaler(hiển thị trong đoạn tiếp theo) vì chúng được chỉ định bằng loại Deploymentvà tên, nginx-deployment.  
**Bước 1: Tạo deployment**  
```sh
apiVersion: apps/v1
  kind: Deployment
  metadata:
    name: nginx-deployment
    labels:
      app: nginx
  spec:
    replicas: 2
    selector:
      matchLabels:
        app: nginx
    template:
      metadata:
        labels:
          app: nginx
      spec:
        containers:
        - name: nginx
          image: nginx:1.7.8
          ports:
          - containerPort: 80
```  
**Bước 2:Tạo VPA**  
```sh
apiVersion: autoscaling.k8s.io/v1beta1
  kind: VerticalPodAutoscaler
  metadata:
    name: nginx-deployment-vpa
  spec:
    targetRef:
      apiVersion: "apps/v1"
      kind:       Deployment
      name:       nginx-deployment
    updatePolicy:
      updateMode: "Off"
```

 
 
 
