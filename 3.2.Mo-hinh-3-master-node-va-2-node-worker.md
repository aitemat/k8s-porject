# Requirement
- OS: Ubuntu 20.04  
- 3 Máy chủ Ubuntu 20 làm Master  
- 2 máy chủ ubuntu 20 làm worker  
- 5 máy đều kết nối internet  
- 45.117.80.52 k8s-master1 : làm Master primary
- 103.101.162.200 k8s-master2: làm Slave
- 45.117.80.150 k8s-master3: làm chức năng HA
- 103.101.163.72 k8s-nodew1: node worker
- 103.101.162.20 k8s-nodew2: node worker
# Cài đặt các config cơ bản cho tất cả các node master và worker
## Add host cho tất cả các node hiểu nhau:  
`vi /etc/hosts`  
Nội dung:  
```sh
45.117.80.52 k8s-master1
103.101.162.200 k8s-master2
45.117.80.150 k8s-master3
103.101.163.72 k8s-nodew1
103.101.162.20 k8s-nodew2
```
## Đặt IP tĩnh (chỉ đặt trong trường hợp máy ảo không thể tự cấp phát IP tĩnh)
`vi etc/netplan/00-installer-config.yaml`  
Chỉnh sửa nội dung:  
```sh
network:
  ethernets:
    ens33:
      dhcp4: no
      dhcp6: no
      addresses: [10.0.0.7/16] #tại đây đổi thành IP cần đặt
      gateway4: 10.0.0.1 # đổi gateway IP mạng
      nameservers:
         addresses: [8.8.8.8, 8.8.4.4]
  version: 2
```
# Cài đặt HAProxy trên k8s-master3 (Master làm load balance)
Chạy lệnh cài đặt HAproxy: ` apt-get install haproxy -y`  
Sau khi cài đặt xong tiến hành edit file config Haproxy: `vi /etc/haproxy/haproxy.cfg`  
Thêm vào cuối nội dung:  
```sh
frontend kubernetes
  bind 45.117.80.150:6443
  mode tcp
  option tcplog
  default_backend kubernetes-master-nodes

backend kubernetes-master-nodes
  mode tcp
  option tcp-check
  balance roundrobin
  server k8s-master1 45.117.80.52:6443 check fall 3 rise 2
  server k8s-master2 103.101.162.200:6443 check fall 3 rise 2

listen stats
    bind 45.117.80.150:8080
    mode http
    stats enable
    stats uri /
    stats realm HAProxy\ Statistics
    stats auth admin:haproxy
```  
Sau đó restart dịch vụ đễ apply cấu hình:  `systemctl status haproxy`  
Link truy cập Haproxy: http://45.117.80.150:8080/Statistics

<img src="/images/haproxy.jpg">

## 1. Cài đặt docker trên tất cả các node
Cài đặt Docker trên các máy chủ bằng các lệnh sau:  
```sh
sudo apt-get update
sudo apt-get install docker.io -y
docker --version
sudo systemctl enable docker
sudo systemctl start docker
sudo systemctl status docker
```
### Tắt tính năng swap
`swapoff -a`  
Kiểm tra trong /etc/fstab nếu mục swap chưa # thì comment lại
## 2.Cài đặt Kubernetes trên 5 node bằng các lệnh sau:
```sh
sudo apt-get update && sudo apt-get install -y apt-transport-https curl
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
sudo touch /etc/apt/sources.list.d/kubernetes.list 
echo "deb https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee -a /etc/apt/sources.list.d/kubernetes.list 
sudo apt-get update 
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
```
## 3. Khởi tạo cluster trên node master đầu tiên bằng lệnh sau:
`sudo kubeadm init --control-plane-endpoint="<IP-Load-blancer>:6443" --upload-certs --pod-network-cidr=<pod-network-cidr>`  
Trong đó:
- `<IP-Load-blancer>` là địa chỉ IP của load balancer nếu bạn sử dụng load balancer, hoặc là địa chỉ IP của node master đầu tiên nếu bạn không sử dụng load balancer. 
- `<pod-network-cidr>` là địa chỉ CIDR cho mạng pod, ví dụ: 10.244.0.0/16.  
Sau khi khởi tạo thành công, lưu lại giá trị token và certificate hash được hiển thị trên màn hình.  
Sinh ra 2 cặp lệnh:  

Lệnh dùng join node worker:  
```sh
kubeadm join 45.117.80.150:6443 --token 5rcyrr.g7zrrb0w2or7ix92 \
        --discovery-token-ca-cert-hash sha256:0e410c227081c8f5acb3f79c31968b3cc1ed46999e7cbfae6199122fe83e03fb
```
Lệnh dùng cho node master join vào:  
```sh
kubeadm join 45.117.80.150:6443 --token 5rcyrr.g7zrrb0w2or7ix92 \
        --discovery-token-ca-cert-hash sha256:0e410c227081c8f5acb3f79c31968b3cc1ed46999e7cbfae6199122fe83e03fb \
        --control-plane --certificate-key 3000ea627497620d9cfe0e623546c14b5f1cc841b97899a710cf304393c51291
```
### Lưu cấu hình `kubectl` trên một node master primary (thực hiện trên k8s-master1)
`mkdir -p $HOME/.kube`  
`sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config`  
`sudo chown $(id -u):$(id -g) $HOME/.kube/config`  
`export KUBECONFIG=/etc/kubernetes/admin.conf`  
`echo "source <(kubectl completion bash)" >> ~/.bashrc`  
### Cài đặt Pod network (thực hiện trên master 1)
`sudo kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml`  
Lệnh kiểm tra:  
`kubectl get pods --all-namespaces`
## 4. Trên các node master tiếp theo, sử dụng lệnh sau để tham gia vào cluster
`sudo kubeadm join <load-balancer-IP>:6443 --token <token-value> --discovery-token-ca-cert-hash sha256:<hash-value> --control-plane --certificate-key <certificate-key-value>`  
Trong đó:  
`<load-balancer-IP>` là địa chỉ IP của load balancer nếu bạn sử dụng load balancer, hoặc là địa chỉ IP của node master đầu tiên nếu bạn không sử dụng load balancer.  
`<token-value>` và `<hash-value>` là giá trị token và certificate hash đã được lưu lại ở bước trước.  
`<certificate-key-value>` là giá trị certificate key cũng được hiển.  
Sau khi chạy lệnh trên ta chạy thêm các lệnh sau trong master k8s-master2 và k8s-master3:  
```sh
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
```
Lệnh trên được sử dụng để sao chép tệp cấu hình của Kubernetes và phân quyền cho người dùng hiện tại để truy cập vào tệp cấu hình đó. Cụ thể, nó thực hiện các bước sau:

Tạo thư mục `.kube` trong thư mục home của người dùng hiện tại bằng lệnh `mkdir -p $HOME/.kube`. Nếu thư mục này không tồn tại, nó sẽ được tạo mới.

Sao chép tệp cấu hình của Kubernetes từ đường dẫn `/etc/kubernetes/admin.conf` đến thư mục `$HOME/.kube/config` bằng lệnh `sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config`. Điều này đảm bảo rằng người dùng hiện tại có thể truy cập vào tệp cấu hình của Kubernetes.

Phân quyền cho người dùng hiện tại để truy cập vào tệp cấu hình bằng lệnh `sudo chown $(id -u):$(id -g) $HOME/.kube/config`. Điều này đảm bảo rằng người dùng hiện tại có quyền truy cập vào tệp cấu hình của Kubernetes.

Sau khi thực hiện các bước trên, người dùng hiện tại có thể sử dụng lệnh kubectl để truy cập và quản lý cụm Kubernetes.
## 5. Sau khi các node master đã tham gia vào cluster, sử dụng lệnh sau để thêm các node worker vào cluster
`sudo kubeadm join <load-balancer-IP>:6443 --token <token-value> --discovery-token-ca-cert-hash sha256:<hash-value>`  
Trong đó:  
`<load-balancer-IP>` là địa chỉ IP của load balancer nếu bạn sử dụng load balancer, hoặc là địa chỉ IP của node master đầu tiên nếu bạn không sử dụng load balancer.  
`<token-value>` và `<hash-value>` là giá trị token và certificate hash đã được lưu lại ở bước trước.  
## 6. Sau khi tất cả các node đã tham gia vào cluster, bạn có thể kiểm tra trạng thái của cluster bằng lệnh sau trên node master đầu tiên
`kubectl get nodes`  
Nếu tất cả các node đều hiển thị là Ready, có nghĩa là cluster đã được triển khai thành công.  
Chú ý: Việc triển khai một cluster Kubernetes với 3 node master và 2 node worker chỉ là một cấu hình cơ bản. Tùy thuộc vào nhu cầu sử dụng và môi trường cụ thể, bạn có thể điều chỉnh số lượng và cấu hình của các node để phù hợp hơn.


## Tổng kết
Trong một mô hình Kubernetes với 3 Node Master và 2 Node Worker, các Node Master đều đảm nhiệm các nhiệm vụ quan trọng trong quản lý và điều khiển cụm Kubernetes. Tuy nhiên, khi có nhiều hơn một Node Master, chỉ có một Node Master đóng vai trò là Node Master chính (primary Node Master), các Node Master khác đóng vai trò là Node Master phụ (secondary Node Master).

Khi cài đặt và triển khai Kubernetes, việc sử dụng nhiều Node Master có thể đảm bảo tính sẵn sàng cao cho hệ thống và giảm thiểu rủi ro do lỗi phần cứng hoặc phần mềm gây ra. Khi một Node Master bị lỗi, các Node Master khác có thể đảm nhận các nhiệm vụ của nó để đảm bảo rằng cụm Kubernetes tiếp tục hoạt động.

Khi hai Node Master phụ tham gia vào Node Master chính, chúng đóng vai trò là bản sao dự phòng của Node Master chính và được sử dụng để đảm bảo sẵn sàng và khả năng chịu lỗi của cụm Kubernetes. Khi Node Master chính bị lỗi, một trong hai Node Master phụ sẽ được chọn để đảm nhận các nhiệm vụ của nó. Khi Node Master chính trở lại, nó sẽ lấy lại vai trò của mình và bắt đầu điều khiển cụm Kubernetes như bình thường.
### Xóa join cluster trên node worker
Sử dụng lệnh kubeadm reset để xóa cài đặt Kubernetes trên node đó:  
`sudo kubeadm reset`  
xóa tất cả các dữ liệu và thông tin của Kubernetes khỏi node đó, bạn có thể sử dụng lệnh sau để xóa tất cả các dữ liệu khỏi node:  
`sudo rm -rf /etc/kubernetes/ /var/lib/kubernetes/ $HOME/.kube/`

